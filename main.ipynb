{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "prompt = \"hi there\"\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm an AI, so I don't have personal desires or preferences. However, I'm here to help and chat with you. Is there anything specific you'd like to talk about or do?\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "message = [\n",
    "    SystemMessage(\n",
    "        content='you are my friend'        \n",
    "    ),\n",
    "    AIMessage(content=\"hi\"),\n",
    "    HumanMessage(content='what do you want to do?')\n",
    "]\n",
    "\n",
    "chat.predict_messages(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are my friend'),\n",
       " AIMessage(content='hi'),\n",
       " HumanMessage(content='what do you want to do?')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "message = [\n",
    "    SystemMessage(\n",
    "        content='you are my friend'        \n",
    "    ),\n",
    "    AIMessage(content=\"hi\"),\n",
    "    HumanMessage(content='what do you want to do?')\n",
    "]\n",
    "\n",
    "message\n",
    "# chat.predict_messages(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template : input_variables=['countryA', 'countryB'] template='what is the distance between {countryA} and {countryB}?'\n",
      "prompt : what is the distance between mexico and thailand?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "template = PromptTemplate.from_template(\n",
    "    'what is the distance between {countryA} and {countryB}?'\n",
    ")\n",
    "\n",
    "prompt = template.format(countryA='mexico', countryB='thailand')\n",
    "print(\"template :\",  template)\n",
    "print(\"prompt :\", prompt)\n",
    "\n",
    "#  chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles).')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI(temperature=0.1)\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'youre my grifriend'),\n",
    "    ('ai', 'hi'),\n",
    "    ('human', 'what is the distance between {countryA} and {countryB}?')\n",
    "])\n",
    "\n",
    "\n",
    "message = template.format_messages(\n",
    "    countryA = 'mexico',\n",
    "    countryB = 'thailand'\n",
    ")\n",
    "chat.predict_messages(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['red', 'blue', 'green', 'yellow', 'orange', 'purple', 'pink', 'brown', 'black', 'white']\n"
     ]
    }
   ],
   "source": [
    "# outputparser\n",
    "# LLM의 응답의 Dtype을 변환해야 할 때를 위해 필요하다. (디폴트값은 언제나 string)\n",
    "# 예시는 프롬프트를 제너레이터로 활용하는 경우.\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser) :\n",
    "    def parse(self, text) :\n",
    "\n",
    "        items = text.strip().split(\",\")        \n",
    "        return list(map(str.strip,items))\n",
    "    \n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    'system', \"you are a list generating machine, Everything you are asked will be answered with a comppa separated list of max {max_items}. Do not reply with anything else.\",\n",
    "    'human',\"{question}\"\n",
    "    ])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items = 10,\n",
    "    question = 'what are the colors    '    \n",
    ")\n",
    "p = CommaOutputParser()\n",
    "result = chat.predict_messages(prompt).content\n",
    "answer = p.parse(result)\n",
    "\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'blue', 'green', 'yellow', 'orange']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chain을 이용해서 위와 동일한 기능을 하는 코드 작성하기\n",
    "# outputparser\n",
    "# LLM의 응답의 Dtype을 변환해야 할 때를 위해 필요하다. (디폴트값은 언제나 string)\n",
    "# 예시는 프롬프트를 제너레이터로 활용하는 경우.\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser) :\n",
    "    def parse(self, text) :\n",
    "\n",
    "        items = text.strip().split(\",\")        \n",
    "        return list(map(str.strip,items))\n",
    "    \n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    'system', \"you are a list generating machine, Everything you are asked will be answered with a comppa separated list of max {max_items}. Do not reply with anything else.\",\n",
    "    'human',\"{question}\"\n",
    "    ])\n",
    "# 이것을 chain이라고 부른다.\n",
    "chain = template | chat | CommaOutputParser()\n",
    "# 요약된 내용 \n",
    "# result = chat.predict_messages(prompt).content\n",
    "# answer = p.parse(result)\n",
    "chain.invoke({\n",
    "    \"max_items\" : 5,\n",
    "    \"question\" : 'what are the colors?'    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Great choice! Chicken Tikka Masala is a delicious Indian dish. To make it vegetarian, you can replace the chicken with a plant-based protein alternative such as tofu or paneer (Indian cottage cheese). Here's how you can modify the recipe:\\n\\nIngredients:\\n- 500g tofu or paneer, cut into bite-sized pieces\\n- 1 cup plain yogurt (use dairy-free yogurt if vegan)\\n- 2 tablespoons lemon juice\\n- 2 tablespoons vegetable oil\\n- 1 large onion, finely chopped\\n- 3 cloves of garlic, minced\\n- 1-inch piece of ginger, grated\\n- 2 teaspoons ground cumin\\n- 2 teaspoons ground coriander\\n- 1 teaspoon turmeric powder\\n- 1 teaspoon paprika\\n- 1 teaspoon garam masala\\n- 1 teaspoon chili powder (adjust to taste)\\n- 1 cup tomato puree\\n- 1 cup coconut cream (or dairy-free heavy cream)\\n- Salt, to taste\\n- Fresh cilantro, chopped (for garnish)\\n\\nInstructions:\\n1. In a bowl, combine the yogurt, lemon juice, 1 teaspoon of ground cumin, 1 teaspoon of ground coriander, turmeric powder, paprika, and chili powder. Mix well.\\n2. Add the tofu or paneer pieces to the marinade and coat them evenly. Let it marinate for at least 1 hour, or overnight in the refrigerator for better flavor.\\n3. Preheat your oven to 400°F (200°C). Place the marinated tofu or paneer on a baking sheet lined with parchment paper and bake for 15-20 minutes, or until slightly charred. Set aside.\\n4. In a large pan, heat the vegetable oil over medium heat. Add the chopped onion and sauté until golden brown.\\n5. Add the minced garlic and grated ginger to the pan and cook for another minute.\\n6. Add the remaining ground cumin, ground coriander, garam masala, and salt. Stir well to combine the spices with the onion mixture.\\n7. Pour in the tomato puree and cook for 5 minutes, stirring occasionally.\\n8. Reduce the heat to low and add the coconut cream (or dairy-free heavy cream). Stir well and let it simmer for 5 minutes.\\n9. Add the cooked tofu or paneer to the sauce and simmer for an additional 5 minutes, allowing the flavors to meld together.\\n10. Taste and adjust the seasoning if needed. If the sauce is too thick, you can add a little water to achieve the desired consistency.\\n11. Garnish with freshly chopped cilantro and serve hot with steamed rice or naan bread.\\n\\nEnjoy your vegetarian Chicken Tikka Masala!\")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain changing\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "\n",
    "chef_prompt  = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are a world_class international chef, you create easy to follow recipies for any type of cuisine with easy to find ingredients.\"),\n",
    "    (\"human\", \"i want to cook {cuisine} food.\")\n",
    "])\n",
    "# 레시피를 전달해주는 모델\n",
    "chef_chain = chef_prompt | chat \n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    \n",
    "(\"system\", \"You are a vegetarian chef specialized on making traditional recipes vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to recipe it.\"), \n",
    "(\"human\", \"{recipe}\")\n",
    "])\n",
    "# 레시피를 채식레시피로 전환해주는 모델\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "# 두 모델의 합체 {}를 통해서 곧바로 인자로 전달할 수 있다는 것이 포인트\n",
    "final_chain = {'recipe' : chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "    'cuisine' : 'indian'\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
